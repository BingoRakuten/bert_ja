import pandas as pd
import numpy as np
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from keras.utils import to_categorical
from sklearn.model_selection import train_test_split

df_train = pd.read_csv("train.tsv",sep="\t")
df_test = pd.read_csv("test.tsv",sep="\t")
df_dev = pd.read_csv("dev.tsv",sep="\t")

y_train = to_categorical(df_train['label'])
y_test = to_categorical(df_test['label'])
y_val = to_categorical(df_dev['label'])


max_features=10000
maxlen = 280

def preprocess(data, tokenizer, maxlen=280):
        return(pad_sequences(tokenizer.texts_to_sequences(data), maxlen=maxlen))


tokenizer = Tokenizer(num_words=max_features, filters="", char_level=True)
tokenizer.fit_on_texts(df_train['text'])

X_train = preprocess(df_train['text'], tokenizer, maxlen)
X_test = preprocess(df_test['text'], tokenizer, maxlen)
X_val = preprocess(df_dev['text'], tokenizer, maxlen)

from keras.layers import Input, Dense, Embedding, Flatten
from keras.layers import SpatialDropout1D
from keras.layers.convolutional import Conv1D, MaxPooling1D
from keras.models import Sequential

model = Sequential()
model.add(Embedding(max_features, 150, input_length=maxlen))
model.add(SpatialDropout1D(0.2))
model.add(Conv1D(32, kernel_size=3, padding='same', activation='relu'))
model.add(MaxPooling1D(pool_size=2))
model.add(Conv1D(64, kernel_size=3, padding='same', activation='relu'))
model.add(MaxPooling1D(pool_size=2))
model.add(Flatten())
model.add(Dense(6, activation='sigmoid'))
model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])

epochs = 10
batch_size = 1000

model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size)

y_preds =  model.predict(X_test)
y_preds =  np.argmax(y_preds, axis=1)
y_true = np.argmax(y_test, axis=1)

from sklearn.metrics import accuracy_score

print("acc:"+str(accuracy_score(y_true, y_preds)))
